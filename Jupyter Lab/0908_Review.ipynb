{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7af6eb-65f7-49a7-a2e9-e0707ed34598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28c4a35-674d-4192-b3f9-9f07fc99623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이트 주소 가져오기 (마지막 페이지)\n",
    "\n",
    "# urlopen할 새로운 변수 생성\n",
    "\n",
    "# read 함수 사용해서 파싱한 데이터를 새 변수에 저장\n",
    "\n",
    "# 마지막 페이지를 find 함수로 찾아서 새 변수에 저장\n",
    "\n",
    "# for문으로 1페이지부터 마지막 페이지까지 돌리기\n",
    "#url(page=) 1~마지막까지\n",
    "# open용\n",
    "# 파싱용\n",
    "# 기사내용이 담긴 ISBN을 붙일 베이스를 만들어둬\n",
    "# 진행 내용을 확인한다\n",
    "# 링크 추가용 빈 리스트\n",
    "# for문 : 셀렉트로 p태그 > a태그\n",
    "#.attrs : href 속성을 가진거에 새로운 변수 값을 주고\n",
    "# if문 : https가 없으면 위에 만든 빈 리스트에 베이스 + ISBN을 해서 append 시킨다.\n",
    "# for문 : append 시킨 빈 리스트였던 것을 가져와서(링크가 들어있음)\n",
    "# 들어있는 링크 오픈용 변수를 만들고\n",
    "# 그거를 파싱하고\n",
    "# 제목이 될 태그를 find_all로 찾아서 변수 부여\n",
    "# 내용이 될 태그를 찾아서 변수 부여\n",
    "# 제일 처음에 만들어둔 데이터프레임과 같은 컬럼 네임을 가진 데이터프레임안에 위 두 변수 집어 넣기\n",
    "# 처음 데이터 프레임과 방금 만든 데이터 프레임을 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81765f6f-dd38-4e5b-b1cc-af17aa8e6942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1페이지 진행중\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m soup \u001b[38;5;241m=\u001b[39m bs(html\u001b[38;5;241m.\u001b[39mread(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 21\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m tmp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[title,context]],columns\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df,tmp_df])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\element.py:2428\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2430\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "url = \"https://www.etnews.com/news/section.html?id1=03&id2=104&page=10000\"\n",
    "html = urlopen(url)\n",
    "soup = bs(html.read(),\"html.parser\")\n",
    "last_page = soup.find('a',{'href':'javascript:;'}).text\n",
    "df = pd.DataFrame(columns=['제목','내용'])\n",
    "for page in range(1,int(last_page)+1):\n",
    "    url = \"https://www.etnews.com/news/section.html?id1=03&id2=104&page=\"+str(page)\n",
    "    html = urlopen(url)\n",
    "    soup = bs(html.read(),'html.parser')\n",
    "    bu = 'https://www.etnews.com'\n",
    "    print(('%d페이지 진행중'%page))\n",
    "    linka = [ ]\n",
    "    for links in soup.select('p > a'):\n",
    "        link1 = links.attrs['href']\n",
    "        if 'https' not in link1:\n",
    "            linka.append(bu+link1)\n",
    "    for link in linka:\n",
    "        html = urlopen(link)\n",
    "        soup = bs(html.read(),\"html.parser\")\n",
    "        title = soup.find_all('h2')[0].text\n",
    "        context = soup.find_all('p')[0].text.replace(\"\\n\",\" \")\n",
    "        tmp_df = pd.DataFrame([[title,context]],columns=df.columns)\n",
    "        df = pd.concat([df,tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d99a1b0-8b9a-4ce7-be10-eb618429975c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b678062-a827-488b-a23a-abe1112f8330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
